<div>
    <!DOCTYPE html>
    <html lang="en">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <title>SKIN AND BONES</title>
        <link rel="icon" href="sword.jpg" type="image/jpg">
        <link rel="stylesheet" href="style__projects.css">
        <link rel="stylesheet" href="https://use.typekit.net/iip6ucd.css">
        <script defer>
            document.addEventListener('DOMContentLoaded', function () {
                document.getElementById("body-content").classList.add('show-content')

            });
        </script>

        <!-- css fix -->
        <link rel="stylesheet" href="addon.css" />
    </head>

    <body>

        <!-- Modal -->
        <div id="modal" class="modal">
            <!-- å·¦ä¾§ç¿»å›¾æ ‡è¯† -->
            <span id="leftLabel" class="modal-label"><::::::::::::::::: }] ---- </span>

            <img id="modalImage" class="modal-image">

            <!-- å³ä¾§ç¿»å›¾æ ‡è¯† -->
            <span id="rightLabel" class="modal-label"> ----[{   :::::::::::::::::></span>

            <!-- <img id="rightImage" src="star_cursor_32px.cur">-->
            <div id="leftContainer" class="image-container">
                <!-- å·¦ç®­å¤´ä¸‹æ–¹çš„æ–‡å­— -->
                <div id="leftText" class="exit-text">ğ˜¤ğ˜­ğ˜ªğ˜¤ğ˜¬ ğ˜µğ˜©ğ˜¦ ğ˜ªğ˜®ğ˜¢ğ˜¨ğ˜¦ ğ˜µğ˜° ğ˜¦ğ˜¹ğ˜ªğ˜µ</div>
            </div>

        </div>

        <div id="body-content">

            <div class="top_container">
                <div class="navigation_container">
                    <a href="index.html">
                        <:::::::::::::::::}] back
                    </a>

                    <a href="bugmod.html">
                        <:::::::::::::::::}] previous
                    </a>

                    <a href="skin_bones2.html">
                        next [{:::::::::::::::::>
                    </a>
                </div>

                <div class="text_container">
                    <div class="description_container">
                        <div class="title_container">
                            <h1 style="font-family: SignPainter;"><tspan style="font-size: smaller;">SKIN AND BONES * 3.0<tspan></h1>
                            <h2><tspan style="color: darkgrey;">ğ’ğ‘œğ“ƒğ“‰ğ’¾ğ“ƒğ“Šğ’¾ğ“ƒğ‘” ğ“…ğ‘’ğ“‡ğ’»ğ‘œğ“‡ğ“‚ğ’¶ğ“ƒğ’¸ğ‘’ ğ“ˆğ‘’ğ“‡ğ’¾ğ‘’ğ“ˆ</tspan></h2>
                        </div>
                        <div class="scroll_container">
                            <tspan style="color: #888;">
                                It's a sound performance project that Roise Muhan Yuan @c6r.6rd and song xin plan to carry forward in the future. <br> <br>
                                Concept:This piece was inspired by a skin condition that Rosie have, which has caused the texture of the skin on parts of the body to change permanently. The altered skin texture reminds her of an armor, merged with the body. By adding fictional body structures with enhanced functions to the body to perform, we created a piece of embodied instrument
                                that draws its concept closer to Peter-Paul Verbeekâ€™s concept of hybrid intentionality. The instrument, once put on, is something that becomes one with the performer. Through this fusion, a new identity is created, where this bodily instrument the performer, together become a trans-humanistic being. In other words, the concept of the instrument disappears and becomes part of the performer. <br> <br>
                                Technical:We used the Myo armband to send the muscle EEG signals to a Max patch, which triggers and controls the development of sounds. And also we use bare Myo armband (MyoWare 2.0Â Muscle Sensor) to control the different sounds.<br><br>
                            </tspan>
                            <tspan style="color: darkgrey;">
                                Our recent project explores the evolving relationship we have with technology, viewing it not just as a toolâ€”which may seem the most obvious interpretationâ€”but as a medium and sometimes even a collaborator. Technology is embedded in the very fabric of our creative process, shaping it and simultaneously being shaped by it. It plays an essential role, and if one were to take a step back, it becomes clear that technology is integral to every aspect of our journey. We are very aware of this reciprocal relationship and enjoy experimenting with it in our collaborative projects. In this sense, technology frequently becomes one of the core themes we like to explore.<br><br>

                                Drawing inspiration from Verbeekâ€™s concept of hybrid intentionality, we were interested in exploring how humans and technology merge. Verbeek argues that humans are never isolated entities but are always directed toward reality, and this relationship is often mediated by technology. If we examine how humans relate to the world through a technological lens, we discover different types of interactions. Hybrid intentionality represents one of these formsâ€”where the human and technological merge. This inspired us to create a kind of technological instrument that could not only be embodied and controlled by the performer but could also merge with the performer to become one. In this way, we aimed for a â€œGesamtkunstwerk,â€ where technology, choreography, movement, and sound are all woven into a unified expression.<br><br>

                                In a sense, our work is an exploration of transhumanist ideas, attempting to transcend the boundaries of the human body through technology. By merging the performer with the instrument, we create a new kind of identityâ€”a transhuman entity that blurs the line between human and machine. This transformation lies at the heart of our work, as we strive to extend the capabilities of the human body through technological augmentation.<br><br>

                                We see this merging of technology and the human form as a growing phenomenon across various industriesâ€”art, music, fashion, gaming, healthcare, and beyond. Itâ€™s a trend that we are excited to be a part of, and our project contributes to this exploration by looking at the potential of wearables as both instruments and extensions of the body. In performance, the generated sound evolves through the interaction between the performer and the wearable, creating a dynamic conversation between movement and sound. The performer generates sound through movement, and simultaneously, that sound influences their subsequent actions. We find this interplay between human and technology, sound and visuals, fascinating, and it's something we want to explore more deeply in our future works.<br><br>

                                Our approach to choreography is also quite unique, as it evolves naturally alongside the performer learning to play the wearable instrument. Sensors capture the performerâ€™s body data, and rather than a pre-planned dance, the performance unfolds organically in response to the generated sounds. This process blurs the lines between choreography and improvisation, emphasizing the fluid and ever-changing relationship between performer and technology.<br><br>

                                In the final iteration of our performance series, we adjusted the interaction between the performer and technology to highlight how real-time audio and visual elements can combine to create new forms of interaction between art and technology.<br><br>
                            </tspan>
                            <tspan style="color: #888;">
                                *Muscle Sensor<br>
                                *Max MSP<br>
                                *Unreal engine5<br>
                                *Arduino<br>
                                *Zbrush<br>
                            </tspan>
                                
                        </div>
                    </div>
                    <div class="credit_container">


                        <h2>
                            <tspan style="color: darkgrey;">ğ“›ğ“¤ğ“ğ“_1:ğ“ ğ“ğ“£ğ“œ_ğ“¡ğ“ğ“¥ğ“”</tspan><br>
                            <tspan style="font-size: smaller;">Ò‰Ì‡ÍŠÍ‘17th October 2024 </tspan><br>
                            <tspan style="font-size: smaller;">
                                Venue MOT, London <br>
                            </tspan> <br> <br>

                        </h2>
                    </div>
                </div>
            </div>












            <div class="bottom_container">

                <div class="video_container">
                    <video src="MOT.mp4" controls autoplay muted loop></video>
                </div>

                <div class="image_container">
                    <img src="skin and bonesMOT.jpg" alt="Image 1" class="clickable-image">
                    <img src="skinandbones3-2.jpg" alt="Image 2" class="clickable-image">
                    <img src="skinandbones3.jpg" alt="Image 3" class="clickable-image">
                </div>

                <div class="others_text" style="margin-bottom: 30%;">
                    <h2>
                        <span style="color:rgb(0, 0, 0); font-size: smaller;">ğ“›ğ“¤ğ“ğ“_1:ğ“ ğ“ğ“£ğ“œ_ğ“¡ğ“ğ“¥ğ“”</span><br>
                        <span style="color:grey; font-size: smaller;">17th October 2024</span><br>
                        <span style="color:grey; font-size: smaller;">Venue MOT, London</span><br>
                        <span style="color: rgb(0, 0, 0); font-size: smaller;">
                            LUNA is a creative and cultural research project focused on quantum music experimentation.<br>
                            The project explores leading music venues as dynamic spaces for pushing the boundaries of creative technologies while sparking new cultural dialogues. Through LUNA, artists experiment with Mothâ€™s cutting-edge quantum music tools and methodsâ€”often still in developmentâ€”curating unique, immersive experiences that blend art, music, and technology.<br>
                            Curated by Atay Ilgun, with creative direction and framing by GÃ¼nseli Yalcinkaya, LUNA delves into early explorations of what a quantum culture might look and sound like. The project transforms live music venues into testing grounds for Mothâ€™s latest innovations, creating experimental, forward-thinking experiences.
                        </span><br><br><br><br><br><br><br><br><br>

                    </h2>
                </div>

                <!-- Modal -->
                <div id="modal" class="modal">
                    <img id="modalImage" class="modal-image">
                </div>

            </div>

            <style>
                /* ç¼©ç•¥å›¾æ ·å¼ */
                .image_container img {
                    cursor: pointer;
                    transition: transform 0.2s ease;
                }

                    .image_container img:hover {
                        transform: scale(1.1);
                    }

                /* ç¼©ç•¥å›¾æ ·å¼ */
                img {
                    margin-right: 0.5vw;
                    height: 100%;
                    cursor: pointer;
                    transition: transform 0.2s ease;
                }

                    img:hover {
                        transform: scale(1.1); /* æ”¾å¤§æ•ˆæœ */
                    }

                /* Modal styles */
                .modal {
                    display: none; /* é»˜è®¤éšè— */
                    position: fixed;
                    top: 0;
                    left: 0;
                    width: 100%;
                    height: 100%;
                    background-color: rgba(0, 0, 0, 0.8); /* é»‘è‰²é€æ˜èƒŒæ™¯ */
                    z-index: 1000;
                    overflow: hidden; /* ç¡®ä¿æ¨¡æ€æ¡†å†…å†…å®¹ä¸ä¼šæº¢å‡º */
                }

                    .modal img {
                        position: absolute; /* ç”¨äºåŠ¨æ€å®šä½ */
                        max-width: 90vw; /* æœ€å¤§å®½åº¦é€‚é…å±å¹• */
                        max-height: 90vh; /* æœ€å¤§é«˜åº¦é€‚é…å±å¹• */
                        border-radius: 10px;
                        box-shadow: 0 0 15px rgba(255, 255, 255, 0.8); /* ç™½è‰²å‘å…‰æ•ˆæœ */
                        transform: translate(-50%, -50%); /* åŸºäºä¸­å¿ƒç‚¹å®šä½ */
                    }
            </style>




        <style>
            #modal {
                position: fixed;
                display: none; /* é»˜è®¤éšè— */
                top: 0;
                left: 0;
                right: 0;
                bottom: 0;
                width: 100%;
                height: 100%;
                background-color: rgba(0, 0, 0, 0.8); /* é»‘è‰²é€æ˜èƒŒæ™¯ */
                z-index: 99;
                /* overflow: hidden; /* ç¡®ä¿æ¨¡æ€æ¡†å†…å†…å®¹ä¸ä¼šæº¢å‡º */
            }

                #modal img {
                    position: absolute; /* ç”¨äºåŠ¨æ€å®šä½ */
                    max-width: 90vw; /* æœ€å¤§å®½åº¦é€‚é…å±å¹• */
                    max-height: 90vh; /* æœ€å¤§é«˜åº¦é€‚é…å±å¹• */
                    height: auto;
                    border-radius: 10px;
                    box-shadow: 0 0 15px rgba(255, 255, 255, 0.8); /* ç™½è‰²å‘å…‰æ•ˆæœ */
                    transform: translate(-50%, -50%); /* åŸºäºä¸­å¿ƒç‚¹å®šä½ */
                }

            /* å·¦å³ç¿»å›¾æ ‡è¯† */
            .modal-label {
                position: absolute;
                top: 50%;
                font-size: 16px;
                color: white;
                font-weight: 100;
                padding: 5px 10px;
                transform: translateY(-50%);
                z-index: 100;
                text-shadow: 0 0 15px rgba(255, 255, 255, 0.8); /* å¤–å‘å…‰æ•ˆæœ */
            }

            #leftLabel {
                left: 10px;
            }

            #rightLabel {
                right: 10px;
            }

            /* å·¦å³ç®­å¤´ */
            #leftImage, #rightImage {
                width: 32px;
                height: 32px;
                position: absolute;
                top: 50%;
                transform: translateY(-50%);
                z-index: 100;
            }

            #leftImage {
                left: 10px;
            }

            #rightImage {
                right: 10px;
            }


            /* åŒ…è£¹å·¦ç®­å¤´å’Œæ–‡å­—çš„å®¹å™¨ */
            .image-container {
                position: absolute;
                left: 23px;
                top: 48%;
                transform: translateY(-50%);
                text-align: center; /* ç¡®ä¿æ–‡å­—å±…ä¸­ */
            }

            /* å·¦ç®­å¤´ä¸‹æ–¹çš„æ–‡å­— */
            .exit-text {
                margin-top: 5px;
                font-size: 9px;
                color: white;
                font-weight: bold;
                text-shadow: 0 0 10px rgba(255, 255, 255, 0.8); /* å¤–å‘å…‰æ•ˆæœ */
            }
        </style>

        <script>
            const images = document.querySelectorAll(".clickable-image");
            const modal = document.getElementById("modal");
            const modalImage = document.getElementById("modalImage");
            var selectedModalItem = null

            function selectImage(img) {
                selectedModalItem = img;
                console.log(`select ${img.nodeName}, ${img.src}`);

                // è®¾ç½®æ¨¡æ€æ¡†å›¾ç‰‡æº
                modalImage.src = img.src;

                // è·å–ç¼©ç•¥å›¾çš„ä¸­å¿ƒç‚¹ä½ç½®
                const rect = img.getBoundingClientRect();
                const centerX = rect.left + rect.width / 2; // ç¼©ç•¥å›¾ä¸­å¿ƒç‚¹ X åæ ‡
                const centerY = rect.top + rect.height / 2; // ç¼©ç•¥å›¾ä¸­å¿ƒç‚¹ Y åæ ‡

                // å°†å›¾ç‰‡åˆå§‹ä½ç½®è®¾ç½®ä¸ºç¼©ç•¥å›¾ä¸­å¿ƒ
                modalImage.style.left = `${centerX}px`;
                modalImage.style.top = `${centerY}px`;

                // ç­‰å¾…å›¾ç‰‡åŠ è½½åå°†å…¶ç§»è‡³å±å¹•ä¸­å¤®
                setTimeout(() => {
                    modalImage.style.left = "50%";
                    modalImage.style.top = "50%";
                }, 0);

                // æ˜¾ç¤ºæ¨¡æ€æ¡†
                modal.style.display = "block";
            }

            // ç‚¹å‡»ç¼©ç•¥å›¾æ—¶æ˜¾ç¤ºæ¨¡æ€æ¡†
            images.forEach(img => {
                img.addEventListener("click", (e) => {
                    selectImage(img);
                });
            });


            // ç‚¹å‡»æ¨¡æ€æ¡†å…³é—­
            modal.addEventListener("click", (e) => {
                let parent = selectedModalItem?.parentNode;
                if (parent == null || !parent.classList.contains("image_container")) {
                    modal.style.display = "none";
                    return;
                }

                let d = Math.floor(e.clientX / modal.clientWidth * 3);
                if (d == 0) {   // left of screen
                    if (selectedModalItem.previousElementSibling) {
                        let prev = selectedModalItem.previousElementSibling;
                        while (prev != null && !prev.classList.contains("clickable-image")) {
                            prev = prev.previousElementSibling;
                        }
                        if (prev != null) {
                            selectImage(prev);
                        }
                    }
                } else if (d == 2) { // right of screen
                    if (selectedModalItem.nextElementSibling) {
                        let next = selectedModalItem.nextElementSibling;
                        while (next != null && !next.classList.contains("clickable-image")) {
                            next = next.nextElementSibling;
                        }
                        if (next != null) {
                            selectImage(next);
                        }
                    }
                } else {    // middle of screen d==1
                    modal.style.display = "none"; // éšè—æ¨¡æ€æ¡†
                    selectedModalItem = null;
                }
            });


        </script>


        </div>


    </body>
</html>
